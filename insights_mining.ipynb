{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/hq/Documents/WorkingRepos/AU_Localization/CD6ME_Ethnic/SAMMMetaEmotionConcised.xlsx'\n",
    "df = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RaceConcised              Asian  Non-Asian\n",
      "EstimatedEmotionConcised                  \n",
      "Negative                     36         56\n",
      "Positive                      1         25\n",
      "Surprise                      5         10\n"
     ]
    }
   ],
   "source": [
    "# Create a crosstab to analyze the distribution between Estimated Emotion and Ethnic_Concised\n",
    "df = df.loc[df['EstimatedEmotionConcised']!='Other']\n",
    "emotion_ethnic_distribution = pd.crosstab(df['EstimatedEmotionConcised'], df['RaceConcised'])\n",
    "\n",
    "# Display the crosstab\n",
    "print(emotion_ethnic_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASME 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_emotion(emotion):\n",
    "    if emotion == 'happiness':\n",
    "        return 'Positive'\n",
    "    elif emotion == 'surprise':\n",
    "        return 'Surprise'\n",
    "    elif emotion == 'others':\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "casme2_annotation = '/home/hq/Documents/data/CASME2/CASME2-coding-updated.xlsx'\n",
    "casme2_annotation_df = pd.read_excel(casme2_annotation)\n",
    "path = '/home/hq/Documents/WorkingRepos/AU_Localization/CD6ME_Ethnic/results_casme2.csv'\n",
    "ethnic_labelled_df = pd.read_csv(path)\n",
    "ethnic_labelled_df['Subject'] = ethnic_labelled_df['Subject'].apply(lambda x: int(x[3:]))\n",
    "ethnic_labelled_df['RaceConcised'] = ethnic_labelled_df['Race'].apply(lambda x: 'Asian' if x >= 2 else 'Non-Asian')\n",
    "merged_df = pd.merge(casme2_annotation_df, ethnic_labelled_df[['Subject', 'Age', 'Gender', 'Race', 'RaceConcised']], on='Subject', how='left')\n",
    "merged_df['EstimatedEmotionConcised'] = merged_df['Estimated Emotion'].apply(categorize_emotion)\n",
    "\n",
    "# Remove columns with \"Unnamed\" in their names\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'CASME2MetaEmotionConcised.xlsx'\n",
    "merged_df.to_excel(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Filename</th>\n",
       "      <th>OnsetFrame</th>\n",
       "      <th>ApexFrame</th>\n",
       "      <th>OffsetFrame</th>\n",
       "      <th>Action Units</th>\n",
       "      <th>Estimated Emotion</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>RaceConcised</th>\n",
       "      <th>EstimatedEmotionConcised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EP02_01f</td>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "      <td>86</td>\n",
       "      <td>12</td>\n",
       "      <td>happiness</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>EP03_02</td>\n",
       "      <td>131</td>\n",
       "      <td>139</td>\n",
       "      <td>161</td>\n",
       "      <td>18</td>\n",
       "      <td>others</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>EP04_02</td>\n",
       "      <td>21</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>EP04_03</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>EP04_04</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_46</td>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>101</td>\n",
       "      <td>17</td>\n",
       "      <td>others</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_47</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_49</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_50</td>\n",
       "      <td>78</td>\n",
       "      <td>99</td>\n",
       "      <td>161</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_51</td>\n",
       "      <td>21</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Filename  OnsetFrame ApexFrame  OffsetFrame Action Units  \\\n",
       "0          1  EP02_01f          46        59           86           12   \n",
       "1          1   EP03_02         131       139          161           18   \n",
       "2          1   EP04_02          21        54           76            4   \n",
       "3          1   EP04_03          31        41           56            4   \n",
       "4          1   EP04_04          23        49           66            4   \n",
       "..       ...       ...         ...       ...          ...          ...   \n",
       "251       26   EP18_46          31        46          101           17   \n",
       "252       26   EP18_47           6        49           86            4   \n",
       "253       26   EP18_49          16        54           80            4   \n",
       "254       26   EP18_50          78        99          161            4   \n",
       "255       26   EP18_51          21        64           81            4   \n",
       "\n",
       "    Estimated Emotion  Age  Gender  Race RaceConcised EstimatedEmotionConcised  \n",
       "0           happiness    2       0     2        Asian                 Positive  \n",
       "1              others    2       0     2        Asian                    Other  \n",
       "2              others    2       0     2        Asian                    Other  \n",
       "3              others    2       0     2        Asian                    Other  \n",
       "4              others    2       0     2        Asian                    Other  \n",
       "..                ...  ...     ...   ...          ...                      ...  \n",
       "251            others    1       1     2        Asian                    Other  \n",
       "252           disgust    1       1     2        Asian                 Negative  \n",
       "253           disgust    1       1     2        Asian                 Negative  \n",
       "254           disgust    1       1     2        Asian                 Negative  \n",
       "255           disgust    1       1     2        Asian                 Negative  \n",
       "\n",
       "[256 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject', 'Filename', 'OnsetFrame', 'ApexFrame', 'OffsetFrame',\n",
       "       'Action Units', 'Estimated Emotion', 'Age', 'Gender', 'Race',\n",
       "       'RaceConcised', 'EstimatedEmotionConcised'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "casme2_concised_df = 'CASME2MetaEmotionConcised.xlsx'\n",
    "samm_concised_df = 'SAMMMetaEmotionConcised.xlsx'\n",
    "casme2_concised_df = pd.read_excel(casme2_concised_df)\n",
    "samm_concised_df = pd.read_excel(samm_concised_df)\n",
    "\n",
    "columns = ['Subject', 'Filename', 'Action Units', 'Estimated Emotion', 'RaceConcised', 'EstimatedEmotionConcised', 'Race']\n",
    "casme2_concised_df = casme2_concised_df[columns]\n",
    "samm_concised_df = samm_concised_df[columns]\n",
    "\n",
    "# try to match subject substring in metadata_csv for aus\n",
    "casme2_concised_df['Subject'] = casme2_concised_df['Subject'].astype(str).str.zfill(2)\n",
    "casme2_concised_df['Dataset'] = 'casme2'\n",
    "samm_concised_df['Subject'] = samm_concised_df['Subject'].astype(str).str.zfill(3)\n",
    "samm_concised_df['Dataset'] = 'samm'\n",
    "\n",
    "\n",
    "concat_df = pd.concat([casme2_concised_df, samm_concised_df], ignore_index=True)\n",
    "concat_df['Estimated Emotion'] = concat_df['Estimated Emotion'].str.lower()\n",
    "# concat_df['Estimated Emotion'] = concat_df['Estimated Emotion'].map({'others':'other'})\n",
    "concat_df = concat_df.loc[~concat_df['Estimated Emotion'].isin(['other', 'others'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to xlsx/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samm_annotations = '/home/hq/Documents/data/SAMM/SAMM_annotation.xlsx'\n",
    "samm_annotations = pd.read_excel(samm_annotations)\n",
    "casme2_annotation = '/home/hq/Documents/data/CASME2/CASME2-coding-updated.xlsx'\n",
    "casme2_annotation = pd.read_excel(casme2_annotation)\n",
    "\n",
    "samm_annotations['Subject'] = samm_annotations['Subject'].astype(str).str.zfill(3)\n",
    "casme2_annotation['Subject'] = casme2_annotation['Subject'].astype(str).str.zfill(2)\n",
    "casme2_annotation['Subject'] = casme2_annotation['Subject'].apply(lambda x: 'sub' + x if len(x) == 2 else x)\n",
    "\n",
    "concat_df['Subject'] = concat_df['Subject'].apply(lambda x: 'sub' + x if len(x) == 2 else x)\n",
    "concat_df_only_ethnic = concat_df.drop_duplicates(subset='Subject')\n",
    "joint_annotation = pd.concat([casme2_annotation, samm_annotations])\n",
    "\n",
    "merged_df = pd.merge(joint_annotation, concat_df_only_ethnic[['Subject', 'RaceConcised', 'Dataset']], on='Subject', how='left')\n",
    "merged_df = merged_df.dropna(subset=['RaceConcised'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Asian', 'Non-Asian'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df['RaceConcised'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race                       0  1    2  3  4\n",
      "EstimatedEmotionConcised                  \n",
      "Negative                  52  4  122  5  9\n",
      "Positive                  25  0   33  0  0\n",
      "Surprise                  10  0   28  0  2\n"
     ]
    }
   ],
   "source": [
    "# Create a crosstab to analyze the distribution between Estimated Emotion and Ethnic_Concised\n",
    "concat_df_distribution = pd.crosstab(concat_df['EstimatedEmotionConcised'], concat_df['Race'])\n",
    "\n",
    "# Display the crosstab\n",
    "print(concat_df_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['Subject'] = concat_df['Subject'].apply(lambda x: 'sub' + x if len(x) == 2 else x)\n",
    "concat_df.to_csv('JointDB_MetaEmotionConcised.csv', index=False)\n",
    "concat_df.to_excel('JointDB_MetaEmotionConcised.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Action Units</th>\n",
       "      <th>Estimated Emotion</th>\n",
       "      <th>RaceConcised</th>\n",
       "      <th>EstimatedEmotionConcised</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub01</td>\n",
       "      <td>EP02_01f</td>\n",
       "      <td>12</td>\n",
       "      <td>happiness</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Positive</td>\n",
       "      <td>casme2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sub01</td>\n",
       "      <td>EP19_05f</td>\n",
       "      <td>4+L10</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>casme2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sub01</td>\n",
       "      <td>EP19_06f</td>\n",
       "      <td>4+5+L10</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>casme2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sub02</td>\n",
       "      <td>EP01_11f</td>\n",
       "      <td>15</td>\n",
       "      <td>repression</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>casme2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sub02</td>\n",
       "      <td>EP02_04f</td>\n",
       "      <td>12+15</td>\n",
       "      <td>repression</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>casme2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>035</td>\n",
       "      <td>035_6_3</td>\n",
       "      <td>R20B</td>\n",
       "      <td>fear</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>samm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>035</td>\n",
       "      <td>035_7_1</td>\n",
       "      <td>A1B+A2C</td>\n",
       "      <td>surprise</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>samm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>035</td>\n",
       "      <td>035_7_2</td>\n",
       "      <td>R14A or 17A or 24A</td>\n",
       "      <td>contempt</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>samm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>036</td>\n",
       "      <td>036_7_3</td>\n",
       "      <td>R10A+25+26</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>samm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>037</td>\n",
       "      <td>037_3_2</td>\n",
       "      <td>T23</td>\n",
       "      <td>anger</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>samm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject  Filename        Action Units Estimated Emotion RaceConcised  \\\n",
       "0     sub01  EP02_01f                  12         happiness        Asian   \n",
       "7     sub01  EP19_05f               4+L10           disgust        Asian   \n",
       "8     sub01  EP19_06f             4+5+L10           disgust        Asian   \n",
       "9     sub02  EP01_11f                  15        repression        Asian   \n",
       "10    sub02  EP02_04f               12+15        repression        Asian   \n",
       "..      ...       ...                 ...               ...          ...   \n",
       "408     035   035_6_3                R20B              fear        Asian   \n",
       "409     035   035_7_1             A1B+A2C          surprise        Asian   \n",
       "410     035   035_7_2  R14A or 17A or 24A          contempt        Asian   \n",
       "411     036   036_7_3          R10A+25+26           disgust        Asian   \n",
       "413     037   037_3_2                 T23             anger        Asian   \n",
       "\n",
       "    EstimatedEmotionConcised Dataset  \n",
       "0                   Positive  casme2  \n",
       "7                   Negative  casme2  \n",
       "8                   Negative  casme2  \n",
       "9                   Negative  casme2  \n",
       "10                  Negative  casme2  \n",
       "..                       ...     ...  \n",
       "408                 Negative    samm  \n",
       "409                 Surprise    samm  \n",
       "410                 Negative    samm  \n",
       "411                 Negative    samm  \n",
       "413                 Negative    samm  \n",
       "\n",
       "[290 rows x 7 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Action Units</th>\n",
       "      <th>Estimated Emotion</th>\n",
       "      <th>RaceConcised</th>\n",
       "      <th>EstimatedEmotionConcised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>EP02_01f</td>\n",
       "      <td>12</td>\n",
       "      <td>happiness</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>EP03_02</td>\n",
       "      <td>18</td>\n",
       "      <td>others</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>EP04_02</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>EP04_03</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>EP04_04</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_46</td>\n",
       "      <td>17</td>\n",
       "      <td>others</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_47</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_49</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_50</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>26</td>\n",
       "      <td>EP18_51</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject  Filename Action Units Estimated Emotion RaceConcised  \\\n",
       "0        01  EP02_01f           12         happiness        Asian   \n",
       "1        01   EP03_02           18            others        Asian   \n",
       "2        01   EP04_02            4            others        Asian   \n",
       "3        01   EP04_03            4            others        Asian   \n",
       "4        01   EP04_04            4            others        Asian   \n",
       "..      ...       ...          ...               ...          ...   \n",
       "251      26   EP18_46           17            others        Asian   \n",
       "252      26   EP18_47            4           disgust        Asian   \n",
       "253      26   EP18_49            4           disgust        Asian   \n",
       "254      26   EP18_50            4           disgust        Asian   \n",
       "255      26   EP18_51            4           disgust        Asian   \n",
       "\n",
       "    EstimatedEmotionConcised  \n",
       "0                   Positive  \n",
       "1                      Other  \n",
       "2                      Other  \n",
       "3                      Other  \n",
       "4                      Other  \n",
       "..                       ...  \n",
       "251                    Other  \n",
       "252                 Negative  \n",
       "253                 Negative  \n",
       "254                 Negative  \n",
       "255                 Negative  \n",
       "\n",
       "[256 rows x 6 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casme2_concised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RaceConcised       Asian  Non-Asian\n",
      "Estimated Emotion                  \n",
      "anger                 20         37\n",
      "contempt               6          6\n",
      "disgust               67          6\n",
      "fear                   6          4\n",
      "happiness             33         25\n",
      "repression            27          0\n",
      "sadness               10          3\n",
      "surprise              30         10\n"
     ]
    }
   ],
   "source": [
    "# Create a crosstab to analyze the distribution between Estimated Emotion and Ethnic_Concised\n",
    "concat_df_distribution = pd.crosstab(concat_df['Estimated Emotion'], concat_df['RaceConcised'])\n",
    "\n",
    "# Display the crosstab\n",
    "print(concat_df_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RaceConcised              Asian  Non-Asian\n",
      "EstimatedEmotionConcised                  \n",
      "Negative                    136         56\n",
      "Positive                     33         25\n",
      "Surprise                     30         10\n"
     ]
    }
   ],
   "source": [
    "# Create a crosstab to analyze the distribution between Estimated Emotion and Ethnic_Concised\n",
    "concat_df_distribution = pd.crosstab(concat_df['EstimatedEmotionConcised'], concat_df['RaceConcised'])\n",
    "\n",
    "# Display the crosstab\n",
    "print(concat_df_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Happiness AU Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_csv = 'cross_dataset_seq.csv'\n",
    "au_csv = pd.read_csv(au_csv)\n",
    "au_csv = au_csv.loc[au_csv['dataset'].isin(['casme2', 'samm'])]\n",
    "aus = ['Subject', 'Filename', \"AU1\", \"AU2\", \"AU4\", \"AU5\", \"AU6\", \"AU7\", \"AU9\", \"AU10\", \"AU12\", \"AU14\", \"AU15\", \"AU17\"]\n",
    "au_csv['Subject'] = au_csv['subject']\n",
    "au_csv['Filename'] = au_csv['material']\n",
    "au_csv = au_csv[aus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(concat_df, au_csv, on=['Subject', 'Filename'], how='left')\n",
    "happiness_df = merged_df.loc[merged_df['Estimated Emotion'] == 'happiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Action Units</th>\n",
       "      <th>Estimated Emotion</th>\n",
       "      <th>RaceConcised</th>\n",
       "      <th>EstimatedEmotionConcised</th>\n",
       "      <th>AU1</th>\n",
       "      <th>AU2</th>\n",
       "      <th>AU4</th>\n",
       "      <th>AU5</th>\n",
       "      <th>AU6</th>\n",
       "      <th>AU7</th>\n",
       "      <th>AU9</th>\n",
       "      <th>AU10</th>\n",
       "      <th>AU12</th>\n",
       "      <th>AU14</th>\n",
       "      <th>AU15</th>\n",
       "      <th>AU17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>EP02_01f</td>\n",
       "      <td>12</td>\n",
       "      <td>happiness</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>EP19_05f</td>\n",
       "      <td>4+L10</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>EP19_06f</td>\n",
       "      <td>4+5+L10</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02</td>\n",
       "      <td>EP01_11f</td>\n",
       "      <td>15</td>\n",
       "      <td>repression</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02</td>\n",
       "      <td>EP02_04f</td>\n",
       "      <td>12+15</td>\n",
       "      <td>repression</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>035</td>\n",
       "      <td>035_6_3</td>\n",
       "      <td>R20B</td>\n",
       "      <td>fear</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>035</td>\n",
       "      <td>035_7_1</td>\n",
       "      <td>A1B+A2C</td>\n",
       "      <td>surprise</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>035</td>\n",
       "      <td>035_7_2</td>\n",
       "      <td>R14A or 17A or 24A</td>\n",
       "      <td>contempt</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>036</td>\n",
       "      <td>036_7_3</td>\n",
       "      <td>R10A+25+26</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>037</td>\n",
       "      <td>037_3_2</td>\n",
       "      <td>T23</td>\n",
       "      <td>anger</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject  Filename        Action Units Estimated Emotion RaceConcised  \\\n",
       "0        01  EP02_01f                  12         happiness        Asian   \n",
       "1        01  EP19_05f               4+L10           disgust        Asian   \n",
       "2        01  EP19_06f             4+5+L10           disgust        Asian   \n",
       "3        02  EP01_11f                  15        repression        Asian   \n",
       "4        02  EP02_04f               12+15        repression        Asian   \n",
       "..      ...       ...                 ...               ...          ...   \n",
       "285     035   035_6_3                R20B              fear        Asian   \n",
       "286     035   035_7_1             A1B+A2C          surprise        Asian   \n",
       "287     035   035_7_2  R14A or 17A or 24A          contempt        Asian   \n",
       "288     036   036_7_3          R10A+25+26           disgust        Asian   \n",
       "289     037   037_3_2                 T23             anger        Asian   \n",
       "\n",
       "    EstimatedEmotionConcised  AU1  AU2  AU4  AU5  AU6  AU7  AU9  AU10  AU12  \\\n",
       "0                   Positive    0    0    0  0.0    0    0    0     0     1   \n",
       "1                   Negative    0    0    1  0.0    0    0    0     1     0   \n",
       "2                   Negative    0    0    1  1.0    0    0    0     1     0   \n",
       "3                   Negative    0    0    0  0.0    0    0    0     0     0   \n",
       "4                   Negative    0    0    0  0.0    0    0    0     0     1   \n",
       "..                       ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "285                 Negative    0    0    0  0.0    0    0    0     0     0   \n",
       "286                 Surprise    1    1    0  0.0    0    0    0     0     0   \n",
       "287                 Negative    0    0    0  0.0    0    0    0     0     0   \n",
       "288                 Negative    0    0    0  0.0    0    0    0     1     0   \n",
       "289                 Negative    0    0    0  0.0    0    0    0     0     0   \n",
       "\n",
       "     AU14  AU15  AU17  \n",
       "0       0     0     0  \n",
       "1       0     0     0  \n",
       "2       0     0     0  \n",
       "3       0     1     0  \n",
       "4       0     1     0  \n",
       "..    ...   ...   ...  \n",
       "285     0     0     0  \n",
       "286     0     0     0  \n",
       "287     1     0     0  \n",
       "288     0     0     0  \n",
       "289     0     0     0  \n",
       "\n",
       "[290 rows x 18 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AU1            0                                          1\n",
      "AU2            0                                      1   0\n",
      "AU4            0                                  1   0   0\n",
      "AU5          0.0                                0.0 0.0 0.0\n",
      "AU6            0                        1         0   0   0\n",
      "AU7            0                     1  0     1   0   0   0\n",
      "AU9            0                     0  0     0   0   0   0\n",
      "AU10           0                  1  0  0     0   0   0   0\n",
      "AU12           0         1        1  1  1     1   1   1   1\n",
      "AU14           0  1      0     1  0  0  0     0   0   0   0\n",
      "AU15           1  0  1   0  1  0  0  0  0     0   0   0   0\n",
      "AU17           0  0  0   0  0  0  0  0  0  1  0   0   0   0\n",
      "RaceConcised                                               \n",
      "Asian          1  3  1  16  1  1  0  0  6  1  1   1   0   1\n",
      "Non-Asian      0  0  0  17  2  0  1  3  1  0  0   0   1   0\n"
     ]
    }
   ],
   "source": [
    "# Create a crosstab to analyze the distribution between Estimated Emotion and Ethnic_Concised\n",
    "au_columns = happiness_df.filter(like='AU').columns.tolist()\n",
    "# Create a crosstab to analyze the distribution of AUs between different races\n",
    "concat_df_distribution = pd.crosstab(index=happiness_df['RaceConcised'], columns=[happiness_df[au] for au in au_columns])\n",
    "\n",
    "# Display the crosstab\n",
    "print(concat_df_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Asian  Non-Asian\n",
      "AU1   0.030303       0.00\n",
      "AU2   0.000000       0.04\n",
      "AU4   0.030303       0.00\n",
      "AU5   0.000000       0.00\n",
      "AU6   0.242424       0.04\n",
      "AU7   0.030303       0.12\n",
      "AU9   0.000000       0.00\n",
      "AU10  0.000000       0.04\n",
      "AU12  0.848485       1.00\n",
      "AU14  0.151515       0.00\n",
      "AU15  0.090909       0.08\n",
      "AU17  0.030303       0.00\n"
     ]
    }
   ],
   "source": [
    "# Group by 'RaceConcised' and calculate the average score of each AU\n",
    "average_au_scores = happiness_df.groupby('RaceConcised')[au_columns].mean()\n",
    "\n",
    "# Display the average AU scores\n",
    "# print(average_au_scores)\n",
    "\n",
    "# Compare the averages between Asian and Non-Asian\n",
    "asian_au_scores = average_au_scores.loc['Asian']\n",
    "non_asian_au_scores = average_au_scores.loc['Non-Asian']\n",
    "\n",
    "# Display the comparison\n",
    "comparison_df = pd.DataFrame({'Asian': asian_au_scores, 'Non-Asian': non_asian_au_scores})\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 18)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "au_localization_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
