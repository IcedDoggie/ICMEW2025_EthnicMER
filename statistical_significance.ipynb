{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = 'JointDB_MetaEmotionConcised.csv'\n",
    "data = pd.read_csv(csv_filename)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize 'EstimatedEmotionConcised' and 'RaceConcised' into a new column\n",
    "emotion_mapping = {'Positive': 0, 'Negative': 1, 'Surprise': 2}  # Example mapping\n",
    "race_mapping = {'Asian': 0, 'Non-Asian': 1}  # Example mapping\n",
    "\n",
    "data['Emotion_Discretized'] = data['EstimatedEmotionConcised'].map(emotion_mapping)\n",
    "data['Race_Discretized'] = data['RaceConcised'].map(race_mapping)\n",
    "\n",
    "# Label AU12 into a binary column\n",
    "# Assuming 'AUs' is a column containing a list or string of AU codes\n",
    "data['AU6_Label'] = data['Action Units'].apply(lambda x: 1 if '6' in str(x) else 0)\n",
    "\n",
    "data['AU12_Label'] = data['Action Units'].apply(lambda x: 1 if '12' in str(x) else 0)\n",
    "\n",
    "\n",
    "data['AU1_Label'] = data['Action Units'].apply(lambda x: 1 if '1' in str(x) else 0)\n",
    "data['AU2_Label'] = data['Action Units'].apply(lambda x: 1 if '2' in str(x) else 0)\n",
    "data['AU5_Label'] = data['Action Units'].apply(lambda x: 1 if '5' in str(x) else 0)\n",
    "data['AU26_Label'] = data['Action Units'].apply(lambda x: 1 if '26' in str(x) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Action Units</th>\n",
       "      <th>Estimated Emotion</th>\n",
       "      <th>RaceConcised</th>\n",
       "      <th>EstimatedEmotionConcised</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Emotion_Discretized</th>\n",
       "      <th>Race_Discretized</th>\n",
       "      <th>AU6_Label</th>\n",
       "      <th>AU12_Label</th>\n",
       "      <th>AU1_Label</th>\n",
       "      <th>AU2_Label</th>\n",
       "      <th>AU5_Label</th>\n",
       "      <th>AU26_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub01</td>\n",
       "      <td>EP02_01f</td>\n",
       "      <td>12</td>\n",
       "      <td>happiness</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Positive</td>\n",
       "      <td>casme2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub01</td>\n",
       "      <td>EP19_05f</td>\n",
       "      <td>4+L10</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>casme2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub01</td>\n",
       "      <td>EP19_06f</td>\n",
       "      <td>4+5+L10</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>casme2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub02</td>\n",
       "      <td>EP01_11f</td>\n",
       "      <td>15</td>\n",
       "      <td>repression</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>casme2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub02</td>\n",
       "      <td>EP02_04f</td>\n",
       "      <td>12+15</td>\n",
       "      <td>repression</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>casme2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>035</td>\n",
       "      <td>035_6_3</td>\n",
       "      <td>R20B</td>\n",
       "      <td>fear</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>samm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>035</td>\n",
       "      <td>035_7_1</td>\n",
       "      <td>A1B+A2C</td>\n",
       "      <td>surprise</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>samm</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>035</td>\n",
       "      <td>035_7_2</td>\n",
       "      <td>R14A or 17A or 24A</td>\n",
       "      <td>contempt</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>samm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>036</td>\n",
       "      <td>036_7_3</td>\n",
       "      <td>R10A+25+26</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>samm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>037</td>\n",
       "      <td>037_3_2</td>\n",
       "      <td>T23</td>\n",
       "      <td>anger</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Negative</td>\n",
       "      <td>samm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject  Filename        Action Units Estimated Emotion RaceConcised  \\\n",
       "0     sub01  EP02_01f                  12         happiness        Asian   \n",
       "1     sub01  EP19_05f               4+L10           disgust        Asian   \n",
       "2     sub01  EP19_06f             4+5+L10           disgust        Asian   \n",
       "3     sub02  EP01_11f                  15        repression        Asian   \n",
       "4     sub02  EP02_04f               12+15        repression        Asian   \n",
       "..      ...       ...                 ...               ...          ...   \n",
       "285     035   035_6_3                R20B              fear        Asian   \n",
       "286     035   035_7_1             A1B+A2C          surprise        Asian   \n",
       "287     035   035_7_2  R14A or 17A or 24A          contempt        Asian   \n",
       "288     036   036_7_3          R10A+25+26           disgust        Asian   \n",
       "289     037   037_3_2                 T23             anger        Asian   \n",
       "\n",
       "    EstimatedEmotionConcised Dataset  Emotion_Discretized  Race_Discretized  \\\n",
       "0                   Positive  casme2                    0                 0   \n",
       "1                   Negative  casme2                    1                 0   \n",
       "2                   Negative  casme2                    1                 0   \n",
       "3                   Negative  casme2                    1                 0   \n",
       "4                   Negative  casme2                    1                 0   \n",
       "..                       ...     ...                  ...               ...   \n",
       "285                 Negative    samm                    1                 0   \n",
       "286                 Surprise    samm                    2                 0   \n",
       "287                 Negative    samm                    1                 0   \n",
       "288                 Negative    samm                    1                 0   \n",
       "289                 Negative    samm                    1                 0   \n",
       "\n",
       "     AU6_Label  AU12_Label  AU1_Label  AU2_Label  AU5_Label  AU26_Label  \n",
       "0            0           1          1          1          0           0  \n",
       "1            0           0          1          0          0           0  \n",
       "2            0           0          1          0          1           0  \n",
       "3            0           0          1          0          1           0  \n",
       "4            0           1          1          1          1           0  \n",
       "..         ...         ...        ...        ...        ...         ...  \n",
       "285          0           0          0          1          0           0  \n",
       "286          0           0          1          1          0           0  \n",
       "287          0           0          1          1          0           0  \n",
       "288          1           0          1          1          1           1  \n",
       "289          0           0          0          1          0           0  \n",
       "\n",
       "[290 rows x 15 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AU6_Label\n",
       "0    46\n",
       "1    12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Emotion_Discretized'] == 0]['AU6_Label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AU12_Label\n",
       "1    53\n",
       "0     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Emotion_Discretized'] == 0]['AU12_Label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.loc[data['Emotion_Discretized'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative_active_df = data.loc[data['Emotion_Discretized'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# au12_active_df = data.loc[data['AU12_Label'] == 1]\n",
    "positive_active_df = data.loc[data['Emotion_Discretized'] == 0]\n",
    "au12_active_df_non_asian = positive_active_df.loc[positive_active_df['Race_Discretized'] == 1]\n",
    "au12_active_df_asian = positive_active_df.loc[positive_active_df['Race_Discretized'] == 0]\n",
    "\n",
    "# Calculate AU12 and AU6 co-occurrence for Asian\n",
    "asian_positive_au12_au6 = au12_active_df_asian[\n",
    "    (au12_active_df_asian['AU12_Label'] == 1) & (au12_active_df_asian['AU6_Label'] == 1)\n",
    "]\n",
    "asian_positive_au12_au6_count = len(asian_positive_au12_au6)\n",
    "\n",
    "# Calculate AU12 and AU6 co-occurrence for Non-Asian\n",
    "non_asian_positive_au12_au6 = au12_active_df_non_asian[\n",
    "    (au12_active_df_non_asian['AU12_Label'] == 1) & (au12_active_df_non_asian['AU6_Label'] == 1)\n",
    "]\n",
    "non_asian_positive_au12_au6_count = len(non_asian_positive_au12_au6)\n",
    "\n",
    "co_occurrence_au6_au12 = pd.concat([asian_positive_au12_au6, non_asian_positive_au12_au6], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 15)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au12_active_df_asian.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# au12_active_df = data.loc[data['AU12_Label'] == 1]\n",
    "surprise_active_df = data.loc[data['Emotion_Discretized'] == 2]\n",
    "au26_active_df_non_asian = surprise_active_df.loc[surprise_active_df['Race_Discretized'] == 1]\n",
    "au26_active_df_asian = surprise_active_df.loc[surprise_active_df['Race_Discretized'] == 0]\n",
    "\n",
    "# # Calculate AU12 and AU6 co-occurrence for Asian\n",
    "# asian_positive_au12_au6 = au12_active_df_asian[\n",
    "#     (au12_active_df_asian['AU12_Label'] == 1) & (au12_active_df_asian['AU6_Label'] == 1)\n",
    "# ]\n",
    "# asian_positive_au12_au6_count = len(asian_positive_au12_au6)\n",
    "\n",
    "# # Calculate AU12 and AU6 co-occurrence for Non-Asian\n",
    "# non_asian_positive_au12_au6 = au12_active_df_non_asian[\n",
    "#     (au12_active_df_non_asian['AU12_Label'] == 1) & (au12_active_df_non_asian['AU6_Label'] == 1)\n",
    "# ]\n",
    "# non_asian_positive_au12_au6_count = len(non_asian_positive_au12_au6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Co-occurring AU6 and AU12 for Asians: 8\n",
      "Number of Co-occurring AU6 and AU12 for Non-asians: 4\n"
     ]
    }
   ],
   "source": [
    "print('Number of Co-occurring AU6 and AU12 for Asians: {}'.format(asian_positive_au12_au6_count))\n",
    "print('Number of Co-occurring AU6 and AU12 for Non-asians: {}'.format(non_asian_positive_au12_au6_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# au26_df = data.loc[data['AU12_Label'] == 1]\n",
    "surprise_active_df = data.loc[data['Emotion_Discretized'] == 2]\n",
    "au26_active_df_non_asian = surprise_active_df.loc[surprise_active_df['Race_Discretized'] == 1]\n",
    "au26_active_df_asian = surprise_active_df.loc[surprise_active_df['Race_Discretized'] == 0]\n",
    "\n",
    "# Calculate AU12 and AU6 co-occurrence for Asian\n",
    "asian_positive_au_active = au26_active_df_asian[\n",
    "    ((au26_active_df_asian['AU1_Label'] == 1) | \n",
    "    (au26_active_df_asian['AU2_Label'] == 1) | \n",
    "    (au26_active_df_asian['AU5_Label'] == 1)) & \n",
    "    (au26_active_df_asian['AU26_Label'] == 1)\n",
    "]\n",
    "asian_positive_au26_count = len(asian_positive_au_active)\n",
    "\n",
    "# Calculate AU12 and AU6 co-occurrence for Non-Asian\n",
    "non_asian_positive_au_active = au26_active_df_non_asian[\n",
    "    ((au26_active_df_non_asian['AU1_Label'] == 1) | \n",
    "    (au26_active_df_non_asian['AU2_Label'] == 1) | \n",
    "    (au26_active_df_non_asian['AU5_Label'] == 1)) & \n",
    "    (au26_active_df_non_asian['AU26_Label'] == 1)\n",
    "]\n",
    "non_asian_positive_au26_count = len(non_asian_positive_au_active)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asian_positive_au_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Co-occurring AU1 2 5 and AU26 for Asians: 1\n",
      "Number of Co-occurring AU1 2 5 and AU26 for Non-asians: 2\n"
     ]
    }
   ],
   "source": [
    "print('Number of Co-occurring AU1 2 5 and AU26 for Asians: {}'.format(asian_positive_au26_count))\n",
    "print('Number of Co-occurring AU1 2 5 and AU26 for Non-asians: {}'.format(non_asian_positive_au26_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #columns_to_chi_squared = ['Emotion_Discretized', 'AU12_Label']\n",
    "# columns_to_chi_squared = ['Race_Discretized', 'AU6_Label']\n",
    "# positive_au12_df = au12_active_df_asian[columns_to_chi_squared]\n",
    "# positive_au12_non_asian_df = au12_active_df_non_asian[columns_to_chi_squared]\n",
    "# positive_au12_df = pd.concat([positive_au12_df, positive_au12_non_asian_df], axis=0)\n",
    "\n",
    "# # columns_to_chi_squared = ['Race_Discretized', 'AU26_Label']\n",
    "# # surprise_au26_df = au26_active_df_asian[columns_to_chi_squared]\n",
    "# # surprise_au26_non_asian_df = au26_active_df_non_asian[columns_to_chi_squared]\n",
    "# # surprise_au26_df = pd.concat([surprise_au26_df, surprise_au26_non_asian_df], axis=0)\n",
    "\n",
    "columns_to_chi_squared = ['AU6_Label', 'AU12_Label']\n",
    "positive_cooccurrence = au12_active_df_non_asian[columns_to_chi_squared]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_cooccurrence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = positive_cooccurrence.groupby('AU12_Label')['AU6_Label'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Ensure 'AU12_Label = 0' is included with all values set to 0\n",
    "if 0 not in contingency_table.index:\n",
    "    contingency_table.loc[0] = [0] * len(contingency_table.columns)\n",
    "\n",
    "#contingency_table_col1 = pd.DataFrame([0, 1])\n",
    "#contingency_table = pd.concat([contingency_table_col1, contingency_table], axis=1)\n",
    "\n",
    "#contingency_table_nonasian = positive_au12_non_asian_df.groupby('Emotion_Discretized')['AU12_Label'].value_counts().unstack(fill_value=0)\n",
    "# contingency_table_col1 = pd.DataFrame([0, 1, 2])\n",
    "#contingency_table_nonasian = pd.concat([contingency_table_col1, contingency_table_nonasian], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AU6_Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU12_Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AU6_Label    0  1\n",
       "AU12_Label       \n",
       "1           21  4\n",
       "0            0  0"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "Chi-Square Statistic: 0.13720017636684298\n",
      "Degrees of Freedom: 1\n",
      "p-value: 0.7110804347751484\n",
      "Expected Frequencies:\n",
      " [[ 5.10810811  1.89189189]\n",
      " [21.89189189  8.10810811]]\n",
      "Odds Ratio: 2.5714285714285716\n",
      "p-value: 0.6471409955755306\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#from scipy.stats import chi2_contingency\n",
    "\n",
    "# Generate random data for a, b, c, and d\n",
    "a, b, c, d = np.random.randint(10, 100, size=4)  # Random integers between 10 and 100\n",
    "\n",
    "# Create the contingency table\n",
    "data = np.array([[a, b],\n",
    "                 [c, d]])\n",
    "print(data.shape)\n",
    "\n",
    "data = contingency_table + 1\n",
    "\n",
    "# Perform the Chi-Square test\n",
    "chi2, p, dof, ex = chi2_contingency(data)\n",
    "\n",
    "# Print the results\n",
    "#print(\"Contingency Table:\\n\", data)\n",
    "print(\"Chi-Square Statistic:\", chi2)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Expected Frequencies:\\n\", ex)\n",
    "\n",
    "\n",
    "# Run Fisher's Exact Test\n",
    "oddsratio, p_value = fisher_exact(data)\n",
    "\n",
    "print(\"Odds Ratio:\", oddsratio)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "Chi-Square Statistic: 0.02432232957595276\n",
      "Degrees of Freedom: 1\n",
      "p-value: 0.8760675630594825\n",
      "Expected Frequencies:\n",
      " [[21.4137931  5.5862069]\n",
      " [ 1.5862069  0.4137931]]\n",
      "Odds Ratio: 4.4\n",
      "p-value: 0.37684729064039413\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#from scipy.stats import chi2_contingency\n",
    "\n",
    "# Generate random data for a, b, c, and d\n",
    "a, b, c, d = np.random.randint(10, 100, size=4)  # Random integers between 10 and 100\n",
    "\n",
    "# Create the contingency table\n",
    "data = np.array([[a, b],\n",
    "                 [c, d]])\n",
    "print(data.shape)\n",
    "\n",
    "data = contingency_table + 1\n",
    "\n",
    "# Perform the Chi-Square test\n",
    "chi2, p, dof, ex = chi2_contingency(data)\n",
    "\n",
    "# Print the results\n",
    "#print(\"Contingency Table:\\n\", data)\n",
    "print(\"Chi-Square Statistic:\", chi2)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Expected Frequencies:\\n\", ex)\n",
    "\n",
    "# Run Fisher's Exact Test\n",
    "oddsratio, p_value = fisher_exact(data)\n",
    "\n",
    "print(\"Odds Ratio:\", oddsratio)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "au_localization_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
